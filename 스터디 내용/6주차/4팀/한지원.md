# 4. 크롤링
크롤링이란 웹페이지의 정보들을 추출하여 정보를 얻어오는 것이다.
## 4.1 urllib 라이브러리를 이용한 웹 페이지 크롤링
URL이란 인터넷 상에 존재하는 리소스들의 위치를 지정하는 용어이다. 
이러한 URL을 다루기 위해 파이썬에서는 urllib를 제공하고 있다. 
이 라이브러리는 웹 사이트에서 HTML 소스 코드를 읽거나, 데이터 다운로드 등을 수행할 수 있다.
### 4.1.1 urllib.request 모듈의 개요
- 웹을 통하여 데이터를 요청하는 기능이 있다.
- 쿠키를 처리해주는 함수가 있다.
- 헤더 등 메타데이터를 바꿔주는 함수가 있다.
```python
urlopen()
```
>1. 네트워크를 통해 원격 객체를 읽고 메모리에 올리는 역할을 수행한다.   
>2. HTML, 이미지 등 파일에 대한 스트림(stream)을 열어 주는 함수이다.   
>3. 메모리에 올린 데이터는 read() 함수를 이용하여 데이터로 만들 수 있다.   
>4. read() 함수로 읽어 들인 데이터는 바이너리 데이터이다.   

```python
url retrieve(url, savename)
```
> url을 savename이라는 이름의 파일로 다운로드합니다.

### 4.1.2 이미지 파일 다운로드 예제
```python
import urllib.request # 라이브러리 읽어 들이기

# URL과 저장 경로 지정하기
url = "https://shared-comic.pstatic.net/thumb/webtoon/626907/thumbnail/title_thumbnail_20150407141027_t83x90.jpg"
savename = "urldownloadO1.png"

# 다운로드
urllib.request.urlretrieve(url, savename)
print('웹에 있는 이미지'+ url + '를 ', end='')
print(savename + " 파일로 저장하였습니다.")
```
### 4.1.3 urlopen() 함수를 이용한 파일 저장
1. urlopen 함수를 이용하여 이미지 객체를 구한다.   
2. open 함수로 파일 객체(모드 :wb)를 구한다.
3. 2번 객체.write(1번 객체.read())을 이용하여 파일을 다운로드한다.

## 4.3 Beautiful Soup 라이브러리를 이용한 웹 페이지 크롤링
Beautiful Soup 라이브러리는 파이썬에서 제공하는 HTML 구문분석 라이브러리로, 
웹의 태그나 클래스의 값을 손쉽게 가져올 수 있도록 지원한다.

### 4.3.1 HTML 문서 이해하기
HTML 기본 문법: https://hansupport.tistory.com/2   
CSS 기본 문법: https://hansupport.tistory.com/3

### 4.3.2 Beautiful Soup
```python
from urllib.request import urlopen
from bs4 import BeautifulSoup

myurl = 'http://comic.naver.com/webtoon/weekday'

# 이 페이지에 request해서 데이터를 가져온 후 변수에 저장한다.
response = urlopen(myurl)

# <class 'http.client.HTTPResponse'>
print(type(response))

# BeautifulSoup()를 이용해서 데이터를 분석한다.
soup = BeautifulSoup(response, 'html.parser')

# Beautiful Soup 객체를 적절한 들여쓰기 형태로 출력해준다.
# print(soup.prettify())

title = soup.find("title").string
print(title)
```

## 새롭게 알게 된 점
1. 데이터 크롤링을 하는 다른 예시: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=hahava&logNo=221237515957
2. HTML 태그의 종류: https://stajun.tistory.com/entry/HTML-%ED%83%9C%EA%B7%B8-%EC%A0%95%EB%A6%AC
3. 데이터 크롤링을 하는 방법과 지켜야 할 윤리: https://pythontoomuchinformation.tistory.com/363

## 문제
스마클 깃허브(https://github.com/sejongsmarcle) 에서 스마클 로고 다운받아서 저장하기
```python
import urllib.request

url = "https://avatars.githubusercontent.com/u/60469393?s=200&v=4"
savename = "smarclelogo.png"

urllib.request.urlretrieve(url, savename)
print('웹에 있는 이미지'+ url + '를 ', end='')
print(savename + " 파일로 저장하였습니다.")
```

![image](https://user-images.githubusercontent.com/101804119/202918254-4179a677-00d0-4370-ab68-9e1310428eae.png)   
저장된 이미지
