# 4. 크롤링
크롤링이란 웹페이지의 정보들을 추출하여 정보를 얻어오는 것이다.
## 4.1 urllib 라이브러리를 이용한 웹 페이지 크롤링
URL이란 인터넷 상에 존재하는 리소스들의 위치를 지정하는 용어이다. 
이러한 URL을 다루기 위해 파이썬에서는 urllib를 제공하고 있다. 
이 라이브러리는 웹 사이트에서 HTML 소스 코드를 읽거나, 데이터 다운로드 등을 수행할 수 있다.
### 4.1.1 urllib.request 모듈의 개요
- 웹을 통하여 데이터를 요청하는 기능이 있다.
- 쿠키를 처리해주는 함수가 있다.
- 헤더 등 메타데이터를 바꿔주는 함수가 있다.
```python
urlopen()
```
>1. 네트워크를 통해 원격 객체를 읽고 메모리에 올리는 역할을 수행한다.   
>2. HTML, 이미지 등 파일에 대한 스트림(stream)을 열어 주는 함수이다.   
>3. 메모리에 올린 데이터는 read() 함수를 이용하여 데이터로 만들 수 있다.   
>4. read() 함수로 읽어 들인 데이터는 바이너리 데이터이다.   

```python
url retrieve(url, savename)
```
> url을 savename이라는 이름의 파일로 다운로드합니다.

### 4.1.2 이미지 파일 다운로드 예제
```python
import urllib.request # 라이브러리 읽어 들이기

# URL과 저장 경로 지정하기
url = "https://shared-comic.pstatic.net/thumb/webtoon/626907/thumbnail/title_thumbnail_20150407141027_t83x90.jpg"
savename = "urldownloadO1.png"

# 다운로드
urllib.request.urlretrieve(url, savename)
print('웹에 있는 이미지'+ url + '를 ', end='')
print(savename + " 파일로 저장하였습니다.")
```
### 4.1.3 urlopen() 함수를 이용한 파일 저장
1. urlopen 함수를 이용하여 이미지 객체를 구한다.   
2. open 함수로 파일 객체(모드 :wb)를 구한다.
3. 2번 객체.write(1번 객체.read())을 이용하여 파일을 다운로드한다.

## 4.3 Beautiful Soup 라이브러리를 이용한 웹 페이지 크롤링
Beautiful Soup 라이브러리는 파이썬에서 제공하는 HTML 구문분석 라이브러리로, 
웹의 태그나 클래스의 값을 손쉽게 가져올 수 있도록 지원한다.

### 4.3.1 HTML 문서 이해하기
HTML 기본 문법: https://hansupport.tistory.com/2   
CSS 기본 문법: https://hansupport.tistory.com/3

### 4.3.2 Beautiful Soup
```python
from urllib.request import urlopen
from bs4 import BeautifulSoup

myurl = 'http://comic.naver.com/webtoon/weekday'

# 이 페이지에 request해서 데이터를 가져온 후 변수에 저장한다.
response = urlopen(myurl)

# <class 'http.client.HTTPResponse'>
print(type(response))

# BeautifulSoup()를 이용해서 데이터를 분석한다.
soup = BeautifulSoup(response, 'html.parser')

# Beautiful Soup 객체를 적절한 들여쓰기 형태로 출력해준다.
# print(soup.prettify())

title = soup.find("title").string
print(title)
```

## 새롭게 알게 된 점
1. 데이터 크롤링을 하는 다른 예시: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=hahava&logNo=221237515957
2. HTML 태그의 종류: https://stajun.tistory.com/entry/HTML-%ED%83%9C%EA%B7%B8-%EC%A0%95%EB%A6%AC
3. 데이터 크롤링을 하는 방법과 지켜야 할 윤리: https://pythontoomuchinformation.tistory.com/363

## 문제
사용자로부터 위키백과에서 목차를 찾을 문서를 입력받아 위키백과의 제목과 목차를 출력하세요.   
각 목차별로 제목은 1. , 2. , 3. 의 순서대로,
소제목은 1.1. , 1.2. , 1.3. 의 순서대로 출력하세요.

hint: from urllib.parse import quote 를 import하여 quote함수를 사용하세요.

```python
#입출력 예시 1
C:\Users\hansupport\Desktop\test\sju\sju\Scripts\python.exe C:/Users/hansupport/Desktop/test/sju/11.21/Q2.py 
위키백과에서 목차를 찾을 문서를 입력하세요:
세종대 #입력
위키백과 제목: 세종대학교
1. 연혁
1.1. 1940~1948 : 설립 초기
1.2. 1948~1954 : 서울가정보육사범학교
1.3. 1954~1978 : 수도여자사범대학
1.4. 1978~1987 : 세종대학
1.5. 1987~2015 : 세종대학교
1.6. 2015~현재 : 개교 80주년
2. 이념
3. 상징
4. 교육
4.1. 강의 방식
4.2. 강의 프로그램
4.3. 졸업요건
4.4. 졸업인증제
5. 위상
5.1. 정부 평가
5.2. 대외 평가
5.3. 국책사업 활동
5.4. 연구 활동
6. 캠퍼스
7. 부속기관
7.1. 도서관
7.2. 박물관
7.3. 교회
7.4. 사회교육원
7.5. 호텔 · 관광시설
7.6. 학술 · 연구시설
7.7. 부속 초등학교
7.8. 부속 고등학교
8. 동문
9. 학생 활동
9.1. 총학생회
9.2. 교내 언론
9.3. 주요 행사
10. 국제 교류
10.1. 하이브리드 프로그램
10.2. 해외직무체험방문학생
11. 같이 보기
12. 각주
13. 외부 링크
```

```python
#입출력 예시 2
위키백과에서 목차를 찾을 문서를 입력하세요:
대한민국 #입력
위키백과 제목: 대한민국
1. 국명
2. 지리
2.1. 지형
2.2. 기후
2.3. 동식물
2.4. 천연자원
3. 역사
3.1. 기원
3.2. 한국의 역사
3.3. 대한민국 임시정부
3.4. 한국의 군정기
3.5. 대한민국 정부 수립
3.6. 6.25 전쟁
3.7. 제1·2공화국
3.8. 제3·4공화국
3.9. 제5공화국
3.10. 제6공화국
3.10.1. 노태우 정부와 문민정부
3.10.2. 국민의 정부와 참여정부
3.10.3. 이명박 정부와 박근혜 정부
3.10.4. 문재인 정부
3.10.5. 윤석열 정부
4. 정치
4.1. 정당
4.2. 정부
4.2.1. 입법부
4.2.2. 행정부
4.2.3. 사법부
4.3. 행정 구역
4.4. 조선민주주의인민공화국의 지위에 대한 분쟁
4.5. 외교
4.5.1. 남북 관계
4.5.2. 한미 관계
4.5.3. 한일 관계
4.5.4. 한중 관계
4.5.5. 한러 관계
5. 국방
5.1. 육군
5.2. 공군
5.3. 해군
5.3.1. 해병대
6. 경제
6.1. 개관
6.1.1. 부채
6.2. 산업
6.2.1. 농업
6.2.2. 공업
6.2.3. 동반 성장
6.3. 교통
6.3.1. 육상 교통
6.3.1.1. 도로
6.3.1.2. 버스
6.3.1.3. 철도
6.3.2. 항공 교통
6.3.3. 해상 교통
7. 사회
7.1. 사회적 소수자
7.1.1. 노동자
7.1.2. 성소수자
7.1.3. 여성
7.1.4. 이주민
7.1.5. 난민
7.2. 인구
7.2.1. 도시의 인구 순위
7.3. 교육과 문화
7.4. 복지
7.5. 사회 갈등
7.5.1. 갈등·소통 지수
7.6. 사회 지표
7.7. 심리
7.7.1. 대응
7.8. 여가
8. 문화
8.1. 언어
8.2. 언론
8.3. 종교
8.4. 예술
8.4.1. 문학
8.4.2. 음악
8.4.3. 미술
8.5. 스포츠
8.6. 한류
8.7. 공휴일
9. 국제 순위
10. 같이 보기
11. 인용
12. 각주
13. 외부 링크
```

```python
#예시 답안
from urllib.request import urlopen
from urllib.parse import quote
from bs4 import BeautifulSoup

print('위키백과에서 목차를 찾을 문서를 입력하세요:')
name = input()
name = quote(name, safe='')

myparser = 'html.parser'
myurl = 'https://ko.wikipedia.org/wiki/' + name
response = urlopen(myurl)
soup = BeautifulSoup(response, myparser)

print('위키백과 제목:', soup.select_one('span.mw-page-title-main').string)

li_list = soup.select('span.sidebar-toc-numb')
title_list = soup.select('span.mw-headline')

for i in range(len(li_list)):
    print('{}. {}'.format(li_list[i].string, title_list[i].string))
```
