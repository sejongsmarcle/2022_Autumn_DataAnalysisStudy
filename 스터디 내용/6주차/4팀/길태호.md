# CHAPTER 4 크롤링
--------------------
웹 페이지의 정보들을 추출하기 위한 프로그램들을 크롤러라고 하고，   
정보를 얻어 오는 동작은 크롤링이라고 한다.


## 4.1 URLLIB 라이브러리를 이용한 웹 페이지 크롤링
--------

urllib를 이용하여 웹 페이지와 관련된 데이터를 쉽게 다룰 수 있다.
웹 사이트에서 html소스코드를 읽거나, 데이터 다운로드 등의 작업을 수행할 수 있다. 

### 4.11 urllib.request 모듈의 개요
------------
-urllib.requst의 합수
-urlopen()   

• 네트워크를 통해 원격 객체를 읽고 메모리에 올리는 역할을 수행   
• HTML, 이미지 등 파일에 대한 스트림(stream)을 열어 주는 함수   
• 메모리에 올린 데이터는 read() 함수를 이용하여 데이터로 만들 수 있음   
• read() 함수로 읽어 들인 데이터는 바이너리 데이터임   

-urlretrieve(url,savename)   

•url을 savename이라는 이름의 파일로 다운로드함   

### 4.1.2 urlretrive()함수를 이용하여 파일 다운로드   
------------
urlretrive()함수를 이용하여 url 주소의 파일을 컴퓨터에 다운로드할 수 있음   

(ex)urllib.request.urlretrieve（url，savename)   

### 4.1.3 urlopen()함수를 이용한 파일 저장   
------------

이미지 파일 다운로드 절차
① urlopen 함수를 이용하여 이미지 객체를 구하기
② open 함수로 파일 객체(wb）를 구하기
③ ②번 객체.write（①번 객체.read（））을 이용하여 파일을 다운로드하기

## 4.3 Beautiful Soup 라이브러리를 이용한 웹페이지 크롤링
-----------

Beautiful Soup 라이브러리는 파이썬에서 제공하는 HTML 구문분석 라이브러리로서 웹의 테그나    
클래스의 값을 손쉽게 가져올 수 있도록 지원한다.    

### 4.3.1 HTML 문서 이해하기
-----------
• 요소: 시작 태그와 종료 태그의 조합을 말합니다.
• 태그: < 기호와 > 기호로 둘러싸인 범위 안에 명령어 이름을 표시합니다.
• 속성: 시작 태그 안에 삽입되며 = 기호와 큰따옴표를 이용하여 값을 지정합니다.
• 값: 속성에 들어가는 실제 값입니다.

#### •부모와 자식테그
모든 테그는 부모와 자식 또는 형제 관계이다. 예를 들어, p태그와 div태그의 부모태그는 body태그이다.   
#### •태그의 속성 다루기

• 객체. seiect_one (<선 택 자>): CSS 선택자로 요소 하나를 추출합니다.   
• 객체.find(tag[:，attributes]): tag라는 태그 중 조건에 맞는 1 번째 태그를 찾아 줍니다.   
• 객체. findall (tag, attributes, limit=숫자): 조건에 맞는 HTML 태그를 전부 찾아 줍니다.   
•객체. attrs ['속성이름']: 해당 속성들을 딕셔너리 형식으로 보여준다.   
•객체. children: 해당 태그의 하위 태그들을 리스트 목록으로 반환한다.    
•객체. parent: 해당 객체의 부모 요소를 찾아 줍니다.    
•객체. find_parent(): 현재 태그의 바로 위 태그를 찾아 줍니다.     
•객체. find_parents(): 현재 태그의 상위에 있는 모든 태그를 찾아 줍니다.     

#### •CSS 선택자 사용하기   

##### • 선택자   
•#: id 속성   
•.: class 속성   
•>: 현재 대상의 바로 하위 child찾기    
•^=: 속성의 값이 ~으로 시작하는 값 찾기    
•$=: 속성의 값이 ~으로 끝나는 값 찾기    
•*=: 속성의 값이 ~을 포함하는 값 찾기    
•nth-of-type(su): su번째 항목 찾기    

##### • 함수        
•객체.select(<선택자>):CSS 선택자로 여러 요소를 리스트로 추출         

##### • string 속성     
해당 요소의 글자부분을 추출한다.    


### 4.3.1 Beautiful Soup  
---------

##### • 크롤링 순서    

1. <div class=”thumb”>인 항목을추출합니다.
2. 반복문을 사용하여<a> 태그의 href 속성을읽어 옵니다.
3. replaceO 함수로치환합니다.
4. splitO 함수를 이용하여요소분해합니다.
5. <img> 태그 title 속성을 읽어 와서제목으로 처리합니다.
6. '?'와 문자는파일 이름으로저장할수 없으므로공백문자로 치환합니다.
7. src 속성을읽어 와서이미지가 존재하는 경로를 취득합니다 .
8. 필요한 정보를 리스트에 추가합니다.
9. 해당 이미지를 각 요일 폴더에 이미지로 저장합니다.
10. 데이터프레임으로만들어 CSV 파일로 저장합니다.
  
  

# CHAPTER 5 데이터 수집, 전처리, 시각화
-------- 
  
## 5.1 모듈 공통 사항
 
• 영문 이름은 실제 소스코드에서 변수 brandName, url 주소는 변수 base_url로 사용한다.    
• 크롤링된 파일들은 '브랜드.CSV’ 형식으로 파일이 저장된다.   
 
#### • 치킨 매장을 위한 공용 모듈의 함수   
 #### • 생성자    
• brandName # 업체 브랜드 이름(예) 'pelicana')    
• url # url 주소    
• soup # Beautiful Soup ^11    
• driver # WebDriver 객체로 굽네 치킨에만 사용됩니다.    
 
 #### • 함수
•get_request_url(): 해당 url 페이지에 대한 응답 객체를 구해주는 함수입니다.      
•getSoupO: 이미 구해 놓은 Beautiful Soup 객체를 반환해주는 함수입니다.     
•save2Csv(): 해당 데이터프레임을 엑셀 파일로 저장해주는 함수입니다.      
  
## 5.1.2 페리카나 치킨의 매장 정보 크롤링
------------
 #### • 카운터 프로그램
conut() 함수를 사용하여 특정 숫자까지만 반복하고 강제종료시킬 수 있다.
  
#### • 페리카나 치킨 매장 1개에 대한 HTML 코드 내용
<pre><code>
<table class="table mt2OH>
<tbody>
<tr>
<td class="t_center">갈산점（이천）</td>
<td>경기도 이천시 갈산로 81（갈산동，102）</td>
<td cl ass=,'t_center">O31-638-832O</td>
<td cl ass="t_center">
<a href="#none" class="b니tton h22 btn_gray"
onclick=" store_viewC127.46*, 37.289*, *갈산점.）'） ;、상세
정보
</a>
</td>
</tr>
... 여기에 <七「>이 반복되고 있습니다.
</tbody>
</table>
</code></pre>
         
  
#### •크롤링 코딩 순서




