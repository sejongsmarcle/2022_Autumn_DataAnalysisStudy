# Ch4. 크롤링

## urllib.request 모듈
- urlopen()
- urlretrieve(url, savename)

## urlopen() 함수를 이용한 파일 저장
1. urlopen 함수를 이용하여 이미지 객체 구하기
2. open 함수로 파일 객체 구하기
3. 2번 객체.write을 이용하여 파일 다운로드

## Beautiful Soup
- 라이브러리를 이용한 웹 페이지 크롤링
- 파이썬에서 크롤링을 해주는 대표적인 라이브러리, HTML 구문분석 라이브러리로서 웹의 태그나 클래스의 값을 손쉽게 가져올 수 있도록 지원

## HTML의 class속성과 id속성에 대하여 추가/조회/삭제
- 객체.select_one(<선택자>) : CSS 선택자로 요소 하나 추출
- 객체.find(tag[, attrivutes]) : tag라는 태그 중 조건에 맞는 1번재 태그 찾기
- 객체.findall(tag, attributes, limit=숫자) : tag – 찾으려는 태그 의미, attrivutes – 속성으로 이루어진 파이썬의 딕셔너리, 내용 – 조건에 맞는 HTML 태그 전부를 찾아줌, limit 속성 – 전체에서 몇 개만 제한하여추출할 때 사용
- 객체.attrs[‘속성이름’] : 해당 속성들을 딕셔너리 형식으로 보여줌
- 객체.children : 해당 태그의 하위 태그들을 리스트 목록으로 반환, for문에서 많이 사용
- 객체.parent : 해당 객체의 부모 요소를 찾아 줌
- 객체.find_parent() : 현재 태그의 바로 위 태그 찾아줌
- 객체.find_parent(): 현재 태그의 상위에 있는 모든 태그를 찾아줌, for문을 이용하여 추출

- 객체.select(<선택자>) : CSS 선택자로 여러 요소를 리스트로 추출
-  string 속성 : 해당 요소의 글자 부분 추출

- select_one() : 요소 1개를 찾고자 할 때 사용
- saveFile() : 웹 페이지에 존재하는 이미지를 로컬 컴퓨터에 저장하기 위한 함수

- - -

# Ch.5 데이터 수집, 전처리, 시각화

## Selenium
- 동적인 웹 페이지나 자바스크립트 등을 이용한 웹 페이지를 크롤링, 드라이버 기능 제공
- 스크린샷 캡쳐 가능
- 일반적인 웹 브라우저와 동작 차이가 적어 디버깅하기 쉬움

- 드라이버 : 웹 브라우저나 DOM 요소나 자바스크립트 동작 가능

## driver 함수
- driver.execute_script(스크립트) : 해당 스크립트 구문 실행
- driver.get(url) : 해당 url 페이지로 이동
- driver.page_source : 해당 url 페이지의 소스 코드를 리턴해주는 속성
- driver.quit() : 해당 WebDriver 객체를 종료
- driver.find_element_by_name(‘q’) : name 속성이 ‘q’라는 요소를 찾음
- driver.save_screenshot(imagefile) : imagefile라는 이름으로 해당 페이지에 대한 스크린샷을 캡처
- driver.implicitly_wait(wait) : (wait)초 동안 잠시 대기

# 추가로 알게 된 내용
- href : h(hypertext) +ref(reference), <a> 태그가 가리키는 URL 정의
- os.path.exists(mypath) : directory, file의 존재 여부 확인하여 True, False를 반환
- driver.find_element_by_id('q') : id가 ‘q’인 요소를 찾음

# 문제
네이버 홈페이지(‘www.naver.com’)로 이동하여 ‘세종대학교’ 검색 실행 후, 이동된 페이지에 대하여 스크린샷 캡처, 3초 후 브라우저 종료
